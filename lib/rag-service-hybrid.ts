import { createClient } from "@supabase/supabase-js"
import OpenAI from "openai"
import { searchWebViaTavily, generateAnswerFromWeb } from "./web-search-service"

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!)
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! })

// Utility: detect language
export function detectLanguage(text: string): "he" | "en" {
  const hebrewPattern = /[\u0590-\u05FF]/
  return hebrewPattern.test(text) ? "he" : "en"
}

// Utility: estimate tokens - IMPROVED
function estimateTokens(text: string): number {
  // Hebrew tends to use more tokens per character than English
  const multiplier = /[\u0590-\u05FF]/.test(text) ? 0.4 : 0.25
  return Math.ceil(text.length * multiplier)
}

// Utility: truncate by sentence - IMPROVED
function truncateText(text: string, maxLength: number): string {
  if (text.length <= maxLength) return text

  // Try to find a sentence break
  const lastStop = Math.max(
    text.lastIndexOf(".", maxLength - 10),
    text.lastIndexOf("!", maxLength - 10),
    text.lastIndexOf("?", maxLength - 10),
  )

  if (lastStop > maxLength * 0.5) {
    return text.slice(0, lastStop + 1)
  }

  // If no good sentence break, just truncate with ellipsis
  return text.slice(0, maxLength) + "..."
}

// Step 1: Create embedding
export async function createEmbedding(text: string): Promise<number[]> {
  const res = await openai.embeddings.create({ model: "text-embedding-ada-002", input: text })
  return res.data[0].embedding
}

// Step 2: Search in internal documents (Supabase RAG)
export async function searchSimilarDocuments(embedding: number[], language: "he" | "en", limit = 3) {
  const { data, error } = await supabase.rpc("match_documents", {
    query_embedding: embedding,
    match_threshold: 0.8,
    match_count: limit,
    filter_language: language,
  })
  if (error) throw error
  return data || []
}

// Step 3: Generate answer from documents - IMPROVED TOKEN MANAGEMENT
async function generateAnswerFromDocs(question: string, docs: any[], lang: "he" | "en") {
  console.log("ğŸ¤– generateAnswerFromDocs - ×”×ª×—×œ×”")
  console.log("  - ×©××œ×”:", question)
  console.log("  - ××¡××›×™×:", docs.length)

  if (docs.length === 0) {
    console.log("âŒ ××™×Ÿ ××¡××›×™× - ××—×–×™×¨ null")
    return null
  }

  // IMPROVED: Better token management
  const MAX_CONTEXT_TOKENS = 6000 // Leave room for the prompt and completion
  let context = ""
  let contextTokens = 0

  // Sort documents by similarity (highest first)
  const sortedDocs = [...docs].sort((a, b) => b.similarity - a.similarity)

  for (const doc of sortedDocs) {
    // Estimate tokens for this document
    const docTitle = `××§×•×¨: ${doc.title}\n`
    const docTitleTokens = estimateTokens(docTitle)

    // Calculate how much content we can include
    const maxContentTokens = MAX_CONTEXT_TOKENS - contextTokens - docTitleTokens - 20 // buffer

    if (maxContentTokens <= 0) break // Stop if we're out of token budget

    // Truncate content to fit token budget
    const truncatedContent = truncateText(doc.plain_text, maxContentTokens * 4) // Convert tokens to chars
    const contentText = `×ª×•×›×Ÿ: ${truncatedContent}\n\n`

    context += docTitle + contentText
    contextTokens += docTitleTokens + estimateTokens(contentText)

    // Stop if we're getting close to the limit
    if (contextTokens > MAX_CONTEXT_TOKENS * 0.9) break
  }

  console.log("ğŸ“Š ×”×§×©×¨:", context.substring(0, 200) + "...")
  console.log("ğŸ“Š ××•××“×Ÿ ×˜×•×§× ×™×:", contextTokens)

  const prompt =
    lang === "he"
      ? `××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£ ×‘×™×©×¨××œ. ×ª×¤×§×™×“×š ×œ×¡×¤×§ ×ª×©×•×‘×•×ª ××“×•×™×§×•×ª, ×××™× ×•×ª ×•×¢×“×›× ×™×•×ª ×œ×©××œ×•×ª ×”×§×©×•×¨×•×ª ×œ××¦×‘×™ ×—×™×¨×•× ×‘×™×©×¨××œ.

×œ×¤× ×™ ××ª×Ÿ ×”×ª×©×•×‘×”, ×§×— ×¦×¢×“ ××—×•×¨×” ×•×—×©×‘ ××” ×”××™×“×¢ ×”××¨×›×–×™ ×”× ×“×¨×© ×›×“×™ ×œ×¢× ×•×ª ×¢×œ ×”×©××œ×” ×‘×¦×•×¨×” ××“×•×™×§×ª ×•×‘×˜×•×—×”.

×—×©×™×‘×” ××•×¤×©×˜×ª:
- ×¢×œ ××” ×”×©××œ×” ×”×–×• ×¢×•×¡×§×ª ×‘×™×¡×•×“×”?
- ××™×–×” ×¡×•×’ ×ª×©×•×‘×” ×¦×¨×™×š ×œ×ª×ª (×¤×¨×•×¦×“×•×¨×œ×™×ª, ×¢×•×‘×“×ª×™×ª, ××‘×•×¡×¡×ª ×‘×˜×™×—×•×ª)?

×ª×©×ª××© ×§×•×“× ×›×œ ×‘××™×“×¢ ×©×œ ×”×”×§×©×¨ ×”×¨×œ×•×•× ×˜×™ ×›×“×™ ×œ×¢× ×•×ª ×‘×¢×‘×¨×™×ª ×‘×¨×•×¨×” ×•×™×“×™×“×•×ª×™×ª ×œ×¦×™×‘×•×¨, ××š ×× ×œ× × ××¦× ×©× ××™×“×¢ ××¡×¤×¨ ×¢×œ×™×™×š ×œ×”×©×ª××© ×‘×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š.

×”×§×©×¨ ×¨×œ×•×•× ×˜×™:
${context}

×©××œ×”:
${question}

×ª×©×•×‘×”:`
      : `You are an AI assistant. Use only the following information.
${context}
Question: ${question}
Answer in English with sources.`

  console.log("ğŸ“ ×¤×¨×•××¤×˜ ×¡×•×¤×™:", prompt.substring(0, 200) + "...")

  const totalTokens = estimateTokens(prompt)
  console.log("ğŸ“Š ××•××“×Ÿ ×˜×•×§× ×™× ×¡×•×¤×™:", totalTokens)

  if (totalTokens > 7500) {
    console.warn("âš ï¸ ××–×”×¨×”: ×—×¨×™×’×ª ×˜×•×§× ×™× ××¤×©×¨×™×ª, ××§×¦×¨ ××ª ×”×¤×¨×•××¤×˜")
    // Use GPT-4o instead which has higher token limit
    try {
      const res = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.1,
        max_tokens: 500,
      })

      const answer = res.choices[0]?.message?.content || ""
      console.log("âœ… ×ª×©×•×‘×” ×”×ª×§×‘×œ×” (gpt-4o):", answer.substring(0, 200) + "...")
      return answer
    } catch (err) {
      console.error("âŒ ×©×’×™××” ×¢× gpt-4o:", err)
      throw err
    }
  }

  console.log("ğŸ”„ ×©×•×œ×— ×‘×§×©×” ×œ-OpenAI (gpt-4)...")

  try {
    const res = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.1,
      max_tokens: 500,
    })

    const answer = res.choices[0]?.message?.content || ""
    console.log("âœ… ×ª×©×•×‘×” ×”×ª×§×‘×œ×”:", answer.substring(0, 200) + "...")
    console.log("ğŸ generateAnswerFromDocs - ×¡×™×•×")

    return answer
  } catch (err) {
    console.error("âŒ ×©×’×™××” ×¢× gpt-4, ×× ×¡×” gpt-4o:", err)

    // Fallback to gpt-4o with more aggressive truncation
    const shorterContext = truncateText(context, context.length * 0.6)
    const shorterPrompt = prompt.replace(context, shorterContext)

    const res = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: shorterPrompt }],
      temperature: 0.1,
      max_tokens: 500,
    })

    const answer = res.choices[0]?.message?.content || ""
    console.log("âœ… ×ª×©×•×‘×” ×”×ª×§×‘×œ×” (gpt-4o fallback):", answer.substring(0, 200) + "...")
    return answer
  }
}

// Step 4: Fallback general GPT-only
async function generateFallbackAnswer(question: string, lang: "he" | "en") {
  console.log("ğŸ”„ generateFallbackAnswer - ×”×ª×—×œ×”")

  const prompt =
    lang === "he"
      ? `××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. ×¢× ×” ×¢×œ ×”×©××œ×” ×”×‘××” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š:

×©××œ×”: ${question}

×ª×©×•×‘×”:`
      : `You are a Home Front Command assistant. Answer the following question based on your general knowledge:

Question: ${question}

Answer:`

  const res = await openai.chat.completions.create({
    model: "gpt-4o", // Use gpt-4o for fallback (higher token limit)
    messages: [{ role: "user", content: prompt }],
    temperature: 0.1,
    max_tokens: 500,
  })

  const answer = res.choices[0]?.message?.content || ""
  const fallbackNote =
    lang === "he"
      ? "\n\n(×”×¢×¨×”: ×ª×©×•×‘×” ×–×• × ×™×ª× ×” ×‘××•×¤×Ÿ ×›×œ×œ×™ ×œ×¤×™ ×”×‘× ×ª ×”××¢×¨×›×ª, ×œ×œ× ×”×¡×ª××›×•×ª ×¢×œ ××¡××š ×××•××ª.)"
      : "\n\n(Note: This answer was provided generally based on the system's understanding, without reliance on verified documents.)"

  console.log("âœ… Fallback answer generated")
  return answer + fallbackNote
}

// Step 5: Router - decide between 'documents' and 'tavily'
async function routeQuery(question: string): Promise<"documents" | "tavily"> {
  console.log("ğŸ§­ Router - ××—×œ×™×˜ ×¢×œ ××¡×œ×•×œ ×¢×‘×•×¨:", question)

  const prompt = `
××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£.
××˜×¨×ª×š ×”×™× ×œ×”×—×œ×™×˜ ×× ×”×©××œ×” ×©×œ ×”××©×ª××© ×“×•×¨×©×ª ××™×“×¢ ×¢×“×›× ×™ ××”××™× ×˜×¨× ×˜ ××• ×©××¤×©×¨ ×œ×”×©×™×‘ ×¢×œ×™×” ×××¡××›×™ ×”×“×¨×›×” ×§×™×™××™×.


×©××œ×•×ª ×©×“×•×¨×©×•×ª ××™× ×˜×¨× ×˜ (×›×ª×•×‘: tavily):
- ×©××œ×•×ª ×¢×œ ××¦×‘ × ×•×›×—×™, ××™×¨×•×¢×™× ××—×¨×•× ×™×, ×–×× ×™× ×¡×¤×¦×™×¤×™×™×
- ××™×“×¢ ×©××ª×¢×“×›×Ÿ ×‘×–××Ÿ ×××ª (×œ××©×œ "××” ×§×•×¨×” ×¢×›×©×™×•?")
- ×–×× ×™× ××• ×ª××¨×™×›×™× ("××™×–×” ××–×¢×§×•×ª ×”×™×• ×”×™×•×?")
- "××ª×™ ×”×™×™×ª×” ×”××–×¢×§×” ×”××—×¨×•× ×”?"
- "××” ×”××¦×‘ ×”×™×•× ×‘×¢×–×”?"
- ×©××œ×•×ª ×¢×œ ×—×“×©×•×ª, ×¢×“×›×•× ×™×, ×ª××¨×™×›×™×

×©××œ×•×ª ×©×œ× ×“×•×¨×©×•×ª ××™× ×˜×¨× ×˜ (×›×ª×•×‘: documents):
- ×”×•×¨××•×ª ×›×œ×œ×™×•×ª, × ×”×œ×™×, ×”×“×¨×›×•×ª
- "××” ×¢×•×©×™× ×‘××–×¢×§×”?"
- "××™×š ××ª×›×•× × ×™× ×œ×¨×¢×™×“×ª ××“××”?"
- "××” ×–×” ××§×œ×˜?"
- "×™×© ××–×¢×§×” ×•×× ×™ ×œ× ×™×•×“×¢×ª ×œ××Ÿ ×œ×œ×›×ª"
- "××™×š ××•×¦××™× ××§×œ×˜?"
- "××” ×œ×¢×©×•×ª ×‘××¦×‘ ×—×™×¨×•×?"
- ×©××œ×•×ª ×¢×œ ×”×›× ×”, ×¦×™×•×“, × ×”×œ×™×, ×”×•×¨××•×ª ×‘×˜×™×—×•×ª

×›×œ×œ ×–×”×‘: ×× ×”×©××œ×” ××ª×—×™×œ×” ×‘"×™×©", "××™×š", "××” ×œ×¢×©×•×ª", "×œ××Ÿ", "××™×¤×”" (×œ×œ× ×–××Ÿ ×¡×¤×¦×™×¤×™) - ×–×” documents

×©××œ×”: ${question}

×”×—×œ×˜×” (×¨×§ tavily ××• documents):`

  const res = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: prompt }],
    max_tokens: 400,
    temperature: 0,
  })

  const content = res.choices[0]?.message?.content?.toLowerCase().trim()
  const decision = content?.includes("tavily") ? "tavily" : "documents"

  console.log("ğŸ§­ Router ×”×—×œ×™×˜:", decision, "×¢×‘×•×¨ ×ª×•×›×Ÿ:", content)
  return decision
}

// Step 6: Hybrid process - IMPROVED ERROR HANDLING
export async function processRAGQuery(question: string): Promise<{
  answer: string
  sources: Array<{
    title: string
    file_name: string
    storage_path: string
    similarity: number
  }>
  usedFallback: boolean
  usedWebSearch: boolean
  error?: string
}> {
  console.log("ğŸš€ processRAGQuery - ×”×ª×—×œ×” ×¢×‘×•×¨:", question)

  const language = detectLanguage(question)
  console.log("ğŸŒ ×©×¤×” ××–×•×”×”:", language)

  try {
    // First determine if we should use web search or documents
    const route = await routeQuery(question)
    console.log("ğŸ“ ××¡×œ×•×œ ×©× ×‘×—×¨:", route)

    if (route === "documents") {
      console.log("ğŸ“š ××¢×‘×“ ×“×¨×š ××¡××›×™× ×¤× ×™××™×™×")

      try {
        const embedding = await createEmbedding(question)
        console.log("ğŸ” Embedding × ×•×¦×¨, ××•×¨×š:", embedding.length)

        const documents = await searchSimilarDocuments(embedding, language)
        console.log("ğŸ“„ ××¡××›×™× × ××¦××•:", documents.length)

        if (documents.length > 0) {
          console.log("ğŸ“Š ××¡××›×™× ×¢× ×“××™×•×Ÿ:")
          documents.forEach((doc, i) => {
            console.log(`  ${i + 1}. ${doc.title} (${Math.round(doc.similarity * 100)}%)`)
          })
        }

        try {
          const answer = await generateAnswerFromDocs(question, documents, language)

          if (!answer || answer.length < 20) {
            console.log("âš ï¸ ×ª×©×•×‘×” ×—×œ×©×” ×××¡××›×™×, ×¢×•×‘×¨ ×œ-fallback ×›×œ×œ×™")
            const fallbackAnswer = await generateFallbackAnswer(question, language)
            return {
              answer: fallbackAnswer,
              sources: [],
              usedFallback: true,
              usedWebSearch: false,
            }
          }

          return {
            answer,
            sources: documents.map((d) => ({
              title: d.title,
              file_name: d.file_name,
              storage_path: d.storage_path,
              similarity: Math.round(d.similarity * 100),
            })),
            usedFallback: false,
            usedWebSearch: false,
          }
        } catch (docError) {
          console.error("âŒ ×©×’×™××” ×‘×™×™×¦×•×¨ ×ª×©×•×‘×” ×××¡××›×™×:", docError)
          console.log("âš ï¸ ×¢×•×‘×¨ ×œ-fallback ×›×œ×œ×™")
          const fallbackAnswer = await generateFallbackAnswer(question, language)
          return {
            answer: fallbackAnswer,
            sources: [],
            usedFallback: true,
            usedWebSearch: false,
            error: docError instanceof Error ? docError.message : JSON.stringify(docError),
          }
        }
      } catch (embeddingError) {
        console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª embedding:", embeddingError)
        console.log("âš ï¸ ×¢×•×‘×¨ ×œ-fallback ×›×œ×œ×™")
        const fallbackAnswer = await generateFallbackAnswer(question, language)
        return {
          answer: fallbackAnswer,
          sources: [],
          usedFallback: true,
          usedWebSearch: false,
          error: embeddingError instanceof Error ? embeddingError.message : JSON.stringify(embeddingError),
        }
      }
    } else {
      console.log("ğŸŒ ××¢×‘×“ ×“×¨×š ×—×™×¤×•×© ××™× ×˜×¨× ×˜×™")
      return await processViaTavily(question, language)
    }
  } catch (err) {
    console.error("âŒ ×©×’×™××” ×›×œ×œ×™×ª ×‘×ª×”×œ×™×š RAG:", err)

    // Last resort fallback
    try {
      const fallbackAnswer = await generateFallbackAnswer(question, language)
      return {
        answer: fallbackAnswer,
        sources: [],
        usedFallback: true,
        usedWebSearch: false,
        error: err instanceof Error ? err.message : JSON.stringify(err),
      }
    } catch (fallbackError) {
      // If even the fallback fails, return a static message
      return {
        answer:
          language === "he"
            ? "××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ××¦×•× ×ª×©×•×‘×” ××”×™×× ×” ×œ×©××œ×” ×–×•. ××•××œ×¥ ×œ×‘×“×•×§ ×‘××ª×¨ ×¤×™×§×•×“ ×”×¢×•×¨×£ ××• ×œ×¤× ×•×ª ×œ×¨×©×•×ª ××•×¡××›×ª."
            : "Sorry, I couldn't find a reliable answer. Please check the Home Front Command website.",
        sources: [],
        usedFallback: true,
        usedWebSearch: false,
        error: `Original error: ${err instanceof Error ? err.message : JSON.stringify(err)}. Fallback error: ${
          fallbackError instanceof Error ? fallbackError.message : JSON.stringify(fallbackError)
        }`,
      }
    }
  }
}

// Step 7: Tavily-based Web Answer
async function processViaTavily(question: string, language: "he" | "en") {
  console.log("ğŸŒ processViaTavily - ×”×ª×—×œ×”")

  const searchResults = await searchWebViaTavily(question)
  if (!searchResults.success || searchResults.results.length === 0) {
    console.log("âš ï¸ Tavily ×œ× ××¦× ×ª×•×¦××•×ª, ×× ×¡×” ×—×™×¤×•×© ×›×œ×œ×™")

    // × × ×¡×” ×—×™×¤×•×© ×›×œ×œ×™ ×™×•×ª×¨
    const generalQuery = question.replace(/××ª×™|××™×¤×”|×›××”/, "").trim()
    const retryResults = await searchWebViaTavily(generalQuery)

    if (retryResults.success && retryResults.results.length > 0) {
      console.log("âœ… ×—×™×¤×•×© ×›×œ×œ×™ ×”×¦×œ×™×—")
      const webAnswer = await generateAnswerFromWeb(question, retryResults.results, language)
      return {
        answer: webAnswer + "\n\n(××™×“×¢ ×–×” ××‘×•×¡×¡ ×¢×œ ×—×™×¤×•×© ×›×œ×œ×™)",
        sources: retryResults.results.map((res) => ({
          title: res.title,
          file_name: `web_result_${res.url}`,
          storage_path: res.url,
          similarity: res.score,
        })),
        usedFallback: false,
        usedWebSearch: true,
      }
    }

    console.log("âš ï¸ ×’× ×—×™×¤×•×© ×›×œ×œ×™ × ×›×©×œ, ×¢×•×‘×¨ ×œ-fallback")
    const fallbackAnswer = await generateFallbackAnswer(question, language)
    return {
      answer: fallbackAnswer,
      sources: [],
      usedFallback: true,
      usedWebSearch: true,
    }
  }

  console.log("âœ… Tavily ××¦× ×ª×•×¦××•×ª:", searchResults.results.length)

  const webAnswer = await generateAnswerFromWeb(question, searchResults.results, language)
  return {
    answer: webAnswer,
    sources: searchResults.results.map((res) => ({
      title: res.title,
      file_name: `web_result_${res.url}`,
      storage_path: res.url,
      similarity: res.score,
    })),
    usedFallback: false,
    usedWebSearch: true,
  }
}

// Chat management functions
export async function createChatSession(userId?: string): Promise<string> {
  try {
    console.log("ğŸ†• ×™×•×¦×¨ chat session ×—×“×© ×¢×‘×•×¨ user:", userId)

    const sessionData: any = {
      created_at: new Date().toISOString(),
    }

    if (userId) {
      sessionData.user_id = userId
      console.log("ğŸ‘¤ ××•×¡×™×£ user_id ×œsession:", userId)
    }

    const { data, error } = await supabase.from("chat_sessions").insert(sessionData).select("id").single()

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª session:", error)
      throw error
    }

    console.log("âœ… Session × ×•×¦×¨ ×‘×”×¦×œ×—×”:", data.id)
    return data.id
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×¡×©×Ÿ:", error)
    throw error
  }
}

export async function saveChatMessage(
  sessionId: string,
  message: string,
  isUser: boolean,
  sources?: Array<{ title: string; file_name: string; storage_path: string; similarity: number }>,
): Promise<void> {
  try {
    console.log(`ğŸ’¾ ×©×•××¨ ×”×•×“×¢×”: ${isUser ? "××©×ª××©" : "×‘×•×˜"} - ${message.substring(0, 50)}...`)
    console.log(`ğŸ“Š ××§×•×¨×•×ª ×œ×©××™×¨×”:`, sources?.length || 0)

    const { error } = await supabase.from("chat_messages").insert({
      session_id: sessionId,
      content: message,
      role: isUser ? "user" : "assistant",
      sources: sources || [],
      created_at: new Date().toISOString(),
    })

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×•×“×¢×”:", error)
      throw error
    }

    console.log("âœ… ×”×•×“×¢×” × ×©××¨×” ×‘×”×¦×œ×—×”")
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×•×“×¢×”:", error)
    throw error
  }
}

export async function getChatHistory(sessionId: string): Promise<
  Array<{
    id: string
    content: string
    role: string
    sources: Array<{ title: string; file_name: string; storage_path: string; similarity: number }>
    created_at: string
  }>
> {
  try {
    console.log("ğŸ“š ×˜×•×¢×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×¦'××˜ ×¢×‘×•×¨ session:", sessionId)

    const { data, error } = await supabase
      .from("chat_messages")
      .select("*")
      .eq("session_id", sessionId)
      .order("created_at", { ascending: true })

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×”:", error)
      throw error
    }

    console.log(`âœ… × ×˜×¢× ×• ${data?.length || 0} ×”×•×“×¢×•×ª`)
    return data || []
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×”:", error)
    return []
  }
}
