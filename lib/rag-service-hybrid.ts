import { createClient } from "@supabase/supabase-js"
import OpenAI from "openai"
import { searchWebViaTavily, generateAnswerFromWeb } from "./web-search-service"

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!)
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! })

// Utility: detect language
export function detectLanguage(text: string): "he" | "en" {
  const hebrewPattern = /[\u0590-\u05FF]/
  return hebrewPattern.test(text) ? "he" : "en"
}

// Utility: estimate tokens
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4)
}

// Utility: truncate by sentence
function truncateText(text: string, maxLength: number): string {
  if (text.length <= maxLength) return text
  const lastStop = Math.max(text.lastIndexOf("."), text.lastIndexOf("!"), text.lastIndexOf("?"))
  return lastStop > maxLength * 0.7 ? text.slice(0, lastStop + 1) : text.slice(0, maxLength) + "..."
}

// Step 1: Create embedding
export async function createEmbedding(text: string): Promise<number[]> {
  const res = await openai.embeddings.create({ model: "text-embedding-ada-002", input: text })
  return res.data[0].embedding
}

// Step 2: Search in internal documents (Supabase RAG)
export async function searchSimilarDocuments(embedding: number[], language: "he" | "en", limit = 3) {
  const { data, error } = await supabase.rpc("match_documents", {
    query_embedding: embedding,
    match_threshold: 0.8,
    match_count: limit,
    filter_language: language,
  })
  if (error) throw error
  return data || []
}

// Step 3: Generate answer from documents
async function generateAnswerFromDocs(question: string, docs: any[], lang: "he" | "en") {
  console.log("ğŸ¤– generateAnswerFromDocs - ×”×ª×—×œ×”")
  console.log("  - ×©××œ×”:", question)
  console.log("  - ××¡××›×™×:", docs.length)

  if (docs.length === 0) {
    console.log("âŒ ××™×Ÿ ××¡××›×™× - ××—×–×™×¨ null")
    return null
  }

  let context = ""
  let len = 0
  for (const doc of docs) {
    const txt = `××§×•×¨: ${doc.title}\n×ª×•×›×Ÿ: ${doc.plain_text}\n\n`
    if (len + txt.length > 2000) {
      const short = truncateText(doc.plain_text, 2000 - len - doc.title.length - 20)
      context += `××§×•×¨: ${doc.title}\n×ª×•×›×Ÿ: ${short}\n\n`
      break
    }
    context += txt
    len += txt.length
  }

  console.log("ğŸ“Š ×”×§×©×¨:", context.substring(0, 200) + "...")

  const prompt =
    lang === "he"
      ? `××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£ ×‘×™×©×¨××œ. ×ª×¤×§×™×“×š ×œ×¡×¤×§ ×ª×©×•×‘×•×ª ××“×•×™×§×•×ª, ×××™× ×•×ª ×•×¢×“×›× ×™×•×ª ×œ×©××œ×•×ª ×”×§×©×•×¨×•×ª ×œ××¦×‘×™ ×—×™×¨×•× ×‘×™×©×¨××œ.

×œ×¤× ×™ ××ª×Ÿ ×”×ª×©×•×‘×”, ×§×— ×¦×¢×“ ××—×•×¨×” ×•×—×©×‘ ××” ×”××™×“×¢ ×”××¨×›×–×™ ×”× ×“×¨×© ×›×“×™ ×œ×¢× ×•×ª ×¢×œ ×”×©××œ×” ×‘×¦×•×¨×” ××“×•×™×§×ª ×•×‘×˜×•×—×”.

×—×©×™×‘×” ××•×¤×©×˜×ª:
- ×¢×œ ××” ×”×©××œ×” ×”×–×• ×¢×•×¡×§×ª ×‘×™×¡×•×“×”?
- ××™×–×” ×¡×•×’ ×ª×©×•×‘×” ×¦×¨×™×š ×œ×ª×ª (×¤×¨×•×¦×“×•×¨×œ×™×ª, ×¢×•×‘×“×ª×™×ª, ××‘×•×¡×¡×ª ×‘×˜×™×—×•×ª)?

×”×©×ª××© ×¨×§ ×‘××™×“×¢ ×”×‘× ×›×“×™ ×œ×¢× ×•×ª ×‘×¢×‘×¨×™×ª ×‘×¨×•×¨×” ×•×™×“×™×“×•×ª×™×ª ×œ×¦×™×‘×•×¨:

×”×§×©×¨ ×¨×œ×•×•× ×˜×™:
{context}

×©××œ×”:
{question}

×ª×©×•×‘×”:`
      : `You are an AI assistant. Use only the following information.
${context}
Question: ${question}
Answer in English with sources.`

  console.log("ğŸ“ ×¤×¨×•××¤×˜ ×¡×•×¤×™:", prompt.substring(0, 200) + "...")

  const totalTokens = estimateTokens(prompt)
  if (totalTokens > 3500) throw new Error("Too many tokens")

  console.log("ğŸ”„ ×©×•×œ×— ×‘×§×©×” ×œ-OpenAI...")

  try {
    const res = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.1,
      max_tokens: 500,
    })

    return res.choices[0]?.message?.content || "××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×™×¦×¨ ×ª×©×•×‘×”."
  } catch (error) {
    console.error("Error generating answer:", error)
    throw new Error("Failed to generate answer")
  }
}

// Fallback prompt
const FALLBACK_PROMPT =
  "××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. ×¢× ×” ×¢×œ ×”×©××œ×” ×”×‘××” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š:\n\n×©××œ×”: {question}\n\n×ª×©×•×‘×”:"

// Fallback general GPT-only
async function generateFallbackAnswer(question: string, lang: "he" | "en") {
  console.log("ğŸ”„ generateFallbackAnswer - ×”×ª×—×œ×”")

  const prompt =
    lang === "he"
      ? `××ª×” ×¢×•×–×¨ ×—×›× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£ ×‘×™×©×¨××œ. ×¢× ×” ×¢×œ ×”×©××œ×” ×”×‘××” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š:

×©××œ×”: ${question}

×ª×©×•×‘×”:`
      : `You are a Home Front Command assistant. Answer the following question based on your general knowledge:

Question: ${question}

Answer:`

  const res = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [{ role: "user", content: prompt }],
    temperature: 0.1,
    max_tokens: 500,
  })

  const answer = res.choices[0]?.message?.content || "××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×™×™×¦×¨ ×ª×©×•×‘×”."
  const fallbackNote =
    lang === "he"
      ? "\n\n(×”×¢×¨×”: ×ª×©×•×‘×” ×–×• × ×™×ª× ×” ×‘××•×¤×Ÿ ×›×œ×œ×™ ×œ×¤×™ ×”×‘× ×ª ×”××¢×¨×›×ª, ×œ×œ× ×”×¡×ª××›×•×ª ×¢×œ ××¡××š ×××•××ª.)"
      : "\n\n(Note: This answer was provided generally based on the system's understanding, without reliance on verified documents.)"

  console.log("âœ… Fallback answer generated")
  return answer + fallbackNote
}

// Step 5: Router - decide between 'documents' and 'tavily'
async function routeQuery(question: string): Promise<"documents" | "tavily"> {
  console.log("ğŸ§­ Router - ××—×œ×™×˜ ×¢×œ ××¡×œ×•×œ ×¢×‘×•×¨:", question)

  const prompt = `
××ª×” ×¢×•×–×¨ ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. ×”×× ×”×©××œ×” ×”×‘××” ×“×•×¨×©×ª ××™×“×¢ ×¢×“×›× ×™ ××”××™× ×˜×¨× ×˜ (×›××• ×—×“×©×•×ª, ××¦×‘ × ×•×›×—×™, ××™×¨×•×¢×™× ××—×¨×•× ×™×) ××• ×©× ×™×ª×Ÿ ×œ×¢× ×•×ª ×¢×œ×™×” ×××¡××›×™ ×”×“×¨×›×” ×§×™×™××™×?

×“×•×’×××•×ª ×œ×©××œ×•×ª ×©×“×•×¨×©×•×ª ××™× ×˜×¨× ×˜:
- "××” ×”××¦×‘ ×”× ×•×›×—×™ ×‘×¢×–×”?"
- "××ª×™ ×”×™×™×ª×” ×”××–×¢×§×” ×”××—×¨×•× ×”?"
- "××” ×”×—×“×©×•×ª ×”×™×•×?"

×“×•×’×××•×ª ×œ×©××œ×•×ª ×©×œ× ×“×•×¨×©×•×ª ××™× ×˜×¨× ×˜:
- "××” ×¢×•×©×™× ×‘××–×¢×§×”?"
- "××™×š ××ª×›×•× × ×™× ×œ×¨×¢×™×“×ª ××“××”?"
- "××” ×–×” ××§×œ×˜?"

×× ×”×©××œ×” ×“×•×¨×©×ª ××™×“×¢ ×¢×“×›× ×™ ××”××™× ×˜×¨× ×˜, ×›×ª×•×‘ ×¨×§: tavily
×× ×”×©××œ×” ×œ× ×“×•×¨×©×ª ××™×“×¢ ×¢×“×›× ×™, ×›×ª×•×‘ ×¨×§: documents

×©××œ×”:
${question}`

  const res = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: prompt }],
    max_tokens: 200,
    temperature: 0,
  })

  const content = res.choices[0]?.message?.content?.toLowerCase().trim()
  const decision = content?.includes("tavily") ? "tavily" : "documents"

  console.log("ğŸ§­ Router ×”×—×œ×™×˜:", decision, "×¢×‘×•×¨ ×ª×•×›×Ÿ:", content)
  return decision
}

// Step 6: Hybrid process
export async function processRAGQuery(question: string) {
  try {
    console.log("Processing RAG query:", question)

    // ×©×œ×‘ 1: ×–×™×”×•×™ ×©×¤×”
    const language = detectLanguage(question)
    console.log("Detected language:", language)

    // ×©×œ×‘ 2: ×™×¦×™×¨×ª embedding
    const embedding = await createEmbedding(question)
    console.log("Created embedding, length:", embedding.length)

    // ×©×œ×‘ 3: ×—×™×¤×•×© ××¡××›×™× ×“×•××™×
    const documents = await searchSimilarDocuments(embedding, language)
    console.log("Found documents:", documents.length)

    // ×©×œ×‘ 4: ×™×¦×™×¨×ª ×ª×©×•×‘×”
    const answer = await generateAnswer(question, documents, true)

    return {
      answer,
      sources: documents.map((doc) => ({
        title: doc.title,
        file_name: doc.file_name,
        similarity: doc.similarity,
      })),
      language,
      documentsFound: documents.length,
    }
  } catch (error) {
    console.error("Error in processRAGQuery:", error)
    return {
      answer: "××¦×˜×¢×¨, ××™×¨×¢×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×©××œ×” ×©×œ×š. ×× × × ×¡×” ×©×•×‘.",
      sources: [],
      language: "he",
      documentsFound: 0,
      error: error instanceof Error ? error.message : "Unknown error",
    }
  }
}

// × ×™×”×•×œ ×¡×©× ×™×
export async function createChatSession(userId: string, title?: string) {
  try {
    const { data, error } = await supabase
      .from("chat_sessions")
      .insert({
        user_id: userId,
        title: title || "×©×™×—×” ×—×“×©×”",
      })
      .select()
      .single()

    if (error) throw error
    return data
  } catch (error) {
    console.error("Error creating chat session:", error)
    throw error
  }
}

// ×©××™×¨×ª ×”×•×“×¢×”
export async function saveChatMessage(sessionId: string, role: "user" | "assistant", content: string) {
  try {
    const { data, error } = await supabase
      .from("chat_messages")
      .insert({
        session_id: sessionId,
        role,
        content,
      })
      .select()
      .single()

    if (error) throw error
    return data
  } catch (error) {
    console.error("Error saving chat message:", error)
    throw error
  }
}

// ×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”
export async function getChatHistory(sessionId: string) {
  try {
    const { data, error } = await supabase
      .from("chat_messages")
      .select("*")
      .eq("session_id", sessionId)
      .order("created_at", { ascending: true })

    if (error) throw error
    return data || []
  } catch (error) {
    console.error("Error getting chat history:", error)
    return []
  }
}

// ×˜×¢×™× ×ª ×¡×©× ×™× ×©×œ ××©×ª××©
export async function getUserChatSessions(userId: string) {
  try {
    const { data, error } = await supabase
      .from("chat_sessions")
      .select("*")
      .eq("user_id", userId)
      .order("created_at", { ascending: false })

    if (error) throw error
    return data || []
  } catch (error) {
    console.error("Error getting user chat sessions:", error)
    return []
  }
}

async function generateAnswer(question: string, documents: any[], useWebSearch: boolean) {
  if (useWebSearch) {
    const route = await routeQuery(question)

    if (route === "tavily") {
      console.log("Route: Tavily")
      const webResults = await searchWebViaTavily(question)
      return await generateAnswerFromWeb(question, webResults)
    } else {
      console.log("Route: Documents")
      return await generateAnswerFromDocs(question, documents, detectLanguage(question))
    }
  } else {
    console.log("Use documents only")
    return await generateAnswerFromDocs(question, documents, detectLanguage(question))
  }
}
