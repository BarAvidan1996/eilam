import { createClient } from "@supabase/supabase-js"
import OpenAI from "openai"

console.log("ğŸ’¥ [processRAGQuery] TEST: ×–×• ×”×’×¨×¡×” ×”× ×›×•× ×” ×©×œ ×”×¤×•× ×§×¦×™×”!")

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!)

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
})

// ×–×™×”×•×™ ×©×¤×”
export function detectLanguage(text: string): "he" | "en" {
  const hebrewPattern = /[\u0590-\u05FF]/
  return hebrewPattern.test(text) ? "he" : "en"
}

// ×¤×•× ×§×¦×™×” ×œ×—×™×ª×•×š ×˜×§×¡×˜ ×—×›×
function truncateText(text: string, maxLength: number): string {
  if (text.length <= maxLength) return text

  // ×—×™×ª×•×š ×‘××©×¤×˜ ×©×œ× ×× ××¤×©×¨
  const truncated = text.substring(0, maxLength)
  const lastSentence = truncated.lastIndexOf(".")
  const lastQuestion = truncated.lastIndexOf("?")
  const lastExclamation = truncated.lastIndexOf("!")

  const lastPunctuation = Math.max(lastSentence, lastQuestion, lastExclamation)

  if (lastPunctuation > maxLength * 0.7) {
    return truncated.substring(0, lastPunctuation + 1)
  }

  return truncated + "..."
}

// ×—×™×©×•×‘ ××¡×¤×¨ ×˜×•×§× ×™× ××©×•×¢×¨ (4 ×ª×•×•×™× = 1 ×˜×•×§×Ÿ ×‘×××•×¦×¢)
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4)
}

// ×‘×“×™×§×” ×¡×× ×˜×™×ª ×¢× GPT ×× ×”×ª×©×•×‘×” ××¡×¤×§×ª - ×ª××™×“ ××ª×‘×¦×¢×ª!
async function isAnswerInsufficientByGPT(question: string, answer: string, language: "he" | "en"): Promise<boolean> {
  console.log("ğŸ§  [isAnswerInsufficientByGPT] *** ×”×ª×—×œ×ª ×‘×“×™×§×ª ××™×›×•×ª ×”×ª×©×•×‘×” ×¢× GPT ***")
  try {
    console.log("ğŸ” [isAnswerInsufficientByGPT] ×©××œ×”:", question)
    console.log("ğŸ“„ [isAnswerInsufficientByGPT] ×ª×©×•×‘×” ×œ×‘×“×™×§×”:", answer.substring(0, 200) + "...")

    const prompt =
      language === "he"
        ? `×©××œ×”: "${question}"\n×ª×©×•×‘×”: "${answer}"\n\n×”×× ×”×ª×©×•×‘×” ××¡×¤×§×ª, ×™×©×™×¨×” ×•×‘×¨×•×¨×”? ×¢× ×” ×¨×§ ×‘"×›×Ÿ" ××• "×œ×".`
        : `Question: "${question}"\nAnswer: "${answer}"\n\nIs the answer direct, accurate and sufficient? Answer only "yes" or "no".`

    console.log("ğŸ“¤ [isAnswerInsufficientByGPT] ×©×•×œ×— ×‘×§×©×” ×œGPT ×œ×‘×“×™×§×ª ××™×›×•×ª...")
    console.log("ğŸ”§ [isAnswerInsufficientByGPT] ××©×ª××© ×‘××•×“×œ: gpt-4o")

    const result = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 5,
      temperature: 0,
    })

    const reply = result.choices[0]?.message?.content?.toLowerCase().trim()
    console.log("ğŸ“¥ [isAnswerInsufficientByGPT] ×ª×’×•×‘×ª GPT RAW:", `"${result.choices[0]?.message?.content}"`)
    console.log("ğŸ“¥ [isAnswerInsufficientByGPT] ×ª×’×•×‘×ª GPT ××¢×•×‘×“×ª:", `"${reply}"`)

    const isInsufficient = reply === "no" || reply === "×œ×"
    console.log(
      `ğŸ¯ [isAnswerInsufficientByGPT] *** ×”×¢×¨×›×” ×¡×•×¤×™×ª: "${reply}" - ${isInsufficient ? "âŒ ×œ× ××¡×¤×§×ª - ×¢×•×‘×¨ ×œWeb Search" : "âœ… ××¡×¤×§×ª - ×××©×™×š ×¢× ×”×ª×©×•×‘×”"} ***`,
    )

    return isInsufficient
  } catch (error) {
    console.error("âŒ [isAnswerInsufficientByGPT] ×©×’×™××” ×‘×‘×“×™×§×ª ××™×›×•×ª ×”×ª×©×•×‘×”:", error)
    console.log("âš ï¸ [isAnswerInsufficientByGPT] ×‘×’×œ×œ ×©×’×™××”, ×××©×™×š ×¢× ×”×ª×©×•×‘×” ×”×§×™×™××ª (×œ× ×¢×•×‘×¨ ×œWeb Search)")
    return false
  }
}

// ×—×™×¤×•×© ×‘××™× ×˜×¨× ×˜ ×¢× OpenAI Web Search
async function searchWebWithOpenAI(
  question: string,
  language: "he" | "en",
): Promise<{ answer: string; usedFallback: boolean; usedWebSearch: boolean }> {
  try {
    console.log("ğŸ” [searchWebWithOpenAI] *** ××ª×—×™×œ ×—×™×¤×•×© ×‘××™× ×˜×¨× ×˜ ×¢× OpenAI Web Search ***")
    console.log("ğŸŒ [searchWebWithOpenAI] ×¢×•×‘×¨ ×œ×—×™×¤×•×© ×‘×¨×©×ª ×œ×§×‘×œ×ª ××™×“×¢ ×¢×“×›× ×™")

    const systemPrompt =
      language === "he"
        ? "××ª×” ×¢×•×–×¨ AI ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. ×—×¤×© ×‘××™× ×˜×¨× ×˜ ×•×ª×Ÿ ×ª×©×•×‘×” ××“×•×™×§×ª, ×¢×“×›× ×™×ª ×•×××™× ×” ×‘×¢×‘×¨×™×ª. ×¦×™×™×Ÿ ××§×•×¨×•×ª ×× ××¤×©×¨."
        : "You are an AI assistant for Home Front Command. Search the web and return an accurate, up-to-date and reliable answer in English. Cite sources when possible."

    const response = await openai.chat.completions.create({
      model: "gpt-4o-search-preview",
      messages: [
        {
          role: "user",
          content: question,
        },
      ],
      max_tokens: 800,
      temperature: 0.3,
    })

    const content = response.choices[0]?.message?.content || "×œ× × ××¦××” ×ª×©×•×‘×” ×¢×“×›× ×™×ª ×‘××™× ×˜×¨× ×˜."

    // ×”×•×¡×¤×ª ×”×¢×¨×” ×¢×œ ××§×•×¨ ×”××™×“×¢
    const webNote =
      language === "he"
        ? "\n\nğŸ“ ×”×¢×¨×”: ××™×“×¢ ×–×” × ××¡×£ ××”××™× ×˜×¨× ×˜ ×•×œ× ××‘×•×¡×¡ ×¢×œ ××¡××›×™× ×¨×©××™×™× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£."
        : "\n\nğŸ“ Note: This information was gathered from the internet and is not based on official Home Front Command documents."

    const finalAnswer = content + webNote

    console.log("ğŸŒ [searchWebWithOpenAI] *** ×ª×©×•×‘×” ××‘×•×¡×¡×ª ××™× ×˜×¨× ×˜ × ×•×¦×¨×” ×‘×”×¦×œ×—×” ***")
    console.log("ğŸ“„ [searchWebWithOpenAI] ××—×–×™×¨ ×ª×©×•×‘×” ××—×™×¤×•×© ×‘×¨×©×ª")

    return {
      answer: finalAnswer,
      usedFallback: true,
      usedWebSearch: true,
    }
  } catch (error) {
    console.error("âŒ [searchWebWithOpenAI] ×©×’×™××” ×‘×—×™×¤×•×© ×‘×¨×©×ª:", error)

    // fallback ×œ×ª×©×•×‘×” ×›×œ×œ×™×ª ×× ×’× Web Search × ×›×©×œ
    return await generateFallbackAnswer(question, language)
  }
}

// ×‘× ×™×™×ª ×”×§×©×¨ ××”××¡××›×™×
function buildContextFromDocuments(
  documents: Array<{
    plain_text: string
    title: string
    file_name: string
    storage_path: string
    similarity: number
  }>,
): string {
  const maxContextLength = 2000
  let context = ""
  let currentLength = 0

  for (const doc of documents) {
    const docText = `××§×•×¨: ${doc.title}\n×ª×•×›×Ÿ: ${doc.plain_text}\n\n`

    if (currentLength + docText.length > maxContextLength) {
      const remainingSpace = maxContextLength - currentLength
      if (remainingSpace > 200) {
        const truncatedText = truncateText(doc.plain_text, remainingSpace - doc.title.length - 20)
        context += `××§×•×¨: ${doc.title}\n×ª×•×›×Ÿ: ${truncatedText}\n\n`
      }
      break
    }

    context += docText
    currentLength += docText.length
  }
  return context
}

// ×™×¦×™×¨×ª embedding
export async function createEmbedding(text: string): Promise<number[]> {
  try {
    console.log("ğŸ”„ ×™×•×¦×¨ embedding ×¢×‘×•×¨:", text.substring(0, 100) + "...")

    const response = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: text,
    })

    console.log("âœ… Embedding × ×•×¦×¨ ×‘×”×¦×œ×—×”, ××•×¨×š:", response.data[0].embedding.length)
    return response.data[0].embedding
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª embedding:", error)
    throw new Error(`×©×’×™××” ×‘×™×¦×™×¨×ª embedding: ${error instanceof Error ? error.message : "×©×’×™××” ×œ× ×™×“×•×¢×”"}`)
  }
}

// ×—×™×¤×•×© ××¡××›×™× ×“×•××™×
export async function searchSimilarDocuments(
  embedding: number[],
  language: "he" | "en",
  limit = 3,
): Promise<
  Array<{
    plain_text: string
    title: string
    file_name: string
    storage_path: string
    similarity: number
  }>
> {
  try {
    console.log(`ğŸ” ××—×¤×© ××¡××›×™× ×‘×©×¤×”: ${language}, limit: ${limit}`)
    console.log("ğŸ“Š Embedding length:", embedding.length)

    const { data: functions, error: functionsError } = await supabase.rpc("match_documents", {
      query_embedding: embedding,
      match_threshold: 0.7,
      match_count: limit,
      filter_language: language,
    })

    if (functionsError) {
      console.error("âŒ ×©×’×™××” ×‘×§×¨×™××” ×œ-RPC match_documents:", functionsError)
      throw new Error(`×©×’×™××” ×‘×—×™×¤×•×© ××¡××›×™×: ${functionsError.message}`)
    }

    console.log(`âœ… × ××¦××• ${functions?.length || 0} ××¡××›×™×`)
    console.log(
      "ğŸ“„ ××¡××›×™× ×©× ××¦××•:",
      functions?.map((doc) => ({
        title: doc.title,
        similarity: doc.similarity,
        storage_path: doc.storage_path,
        text_preview: doc.plain_text?.substring(0, 100) + "...",
      })),
    )

    return functions || []
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×—×™×¤×•×© ××¡××›×™×:", error)
    throw error
  }
}

// ×™×¦×™×¨×ª ×ª×©×•×‘×” ×¢× step-back prompting ×•× ×™×”×•×œ ×˜×•×§× ×™× ×—×›×
export async function generateAnswer(
  question: string,
  documents: Array<{
    plain_text: string
    title: string
    file_name: string
    storage_path: string
    similarity: number
  }>,
  language: "he" | "en",
): Promise<{ answer: string; usedFallback: boolean; usedWebSearch?: boolean }> {
  console.log("ğŸ¤– [generateAnswer] *** 1. ×”×ª×—×œ×ª ×”×¤×•× ×§×¦×™×” ***")
  try {
    console.log("ğŸ¤– [generateAnswer] *** 2. × ×›× ×¡ ×œ-try block ***")
    console.log("ğŸ¤– [generateAnswer] *** 3. ×©××œ×”:", question, "***")
    console.log("ğŸ“š [generateAnswer] *** 4. ××¡××›×™× ×©× ××¦××•:", documents.length, "***")

    // ğŸ§ª ×©×œ×‘ 1: ×× ××™×Ÿ ×›×œ×œ ××¡××›×™× â†’ ××™×“ ×¢×•×‘×¨ ×œÖ¾Web Search
    console.log("ğŸ¤– [generateAnswer] *** 5. ×‘×•×“×§ ×× ××™×Ÿ ××¡××›×™× ×›×œ×œ ***")
    if (documents.length === 0) {
      console.log("âš ï¸ [generateAnswer] *** 6. ×œ× × ××¦××• ××¡××›×™× ×›×œ×œ, ××¤×¢×™×œ Web Search ***")
      const webSearchResult = await searchWebWithOpenAI(question, language)
      console.log("ğŸ¤– [generateAnswer] *** 7. Web Search result:", webSearchResult, "***")
      return webSearchResult
    }

    console.log("ğŸ§± [generateAnswer] *** 8. ×‘×•× ×” ×”×§×©×¨ ××”××¡××›×™× ***")

    // ğŸ§± ×©×œ×‘ 2: ×‘× ×™×™×ª ×”×§×©×¨ ××”××¡××›×™×
    console.log("ğŸ¤– [generateAnswer] *** 9. ×§×•×¨× ×œ-buildContextFromDocuments ***")
    const context = buildContextFromDocuments(documents)
    console.log("ğŸ¤– [generateAnswer] *** 10. buildContextFromDocuments ×”×•×©×œ× ***")

    console.log(
      `ğŸ“Š [generateAnswer] *** 11. ××•×¨×š ×”×§×©×¨: ${context.length} ×ª×•×•×™× (${estimateTokens(context)} ×˜×•×§× ×™× ××©×•×¢×¨×™×) ***`,
    )

    console.log("ğŸ¤– [generateAnswer] *** 12. ××›×™×Ÿ system prompt ***")
    const systemPrompt =
      language === "he"
        ? `××ª×” ×¢×•×–×¨ AI ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. ×”×©×ª××© ×¨×§ ×‘××™×“×¢ ×”××¡×•×¤×§. ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢, ×¦×™×™×Ÿ ×–××ª ×‘××¤×•×¨×©.`
        : `You are an AI assistant for Home Front Command. Use only the provided information. If there's insufficient information, state this explicitly.`

    console.log("ğŸ¤– [generateAnswer] *** 13. ××›×™×Ÿ user prompt ***")
    const userPrompt =
      language === "he"
        ? `×©××œ×”: ${question}\n\n××™×“×¢:\n${context}\n\n×¢× ×” ×‘×¦×•×¨×” ××“×•×™×§×ª. ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢, ×××•×¨ ×–××ª.`
        : `Question: ${question}\n\nInformation:\n${context}\n\nAnswer accurately. If there's insufficient information, say so.`

    console.log("ğŸ¤– [generateAnswer] *** 14. ××—×©×‘ ×˜×•×§× ×™× ***")
    const totalTokens = estimateTokens(systemPrompt + userPrompt)
    console.log(`ğŸ“Š [generateAnswer] *** 15. ×˜×•×§× ×™× ××©×•×¢×¨×™× ×œ×‘×§×©×”: ${totalTokens} ***`)

    console.log("ğŸ¤– [generateAnswer] *** 16. ×‘×•×“×§ ×× ×™×•×ª×¨ ××“×™ ×˜×•×§× ×™× ***")
    if (totalTokens > 3500) {
      console.log("âš ï¸ [generateAnswer] *** 17. ×™×•×ª×¨ ××“×™ ×˜×•×§× ×™×, ×¢×•×‘×¨ ×œ-Web Search ***")
      return await searchWebWithOpenAI(question, language)
    }

    console.log("ğŸ”„ [generateAnswer] *** 18. ×©×•×œ×— ×‘×§×©×” ×œ-OpenAI... ***")

    console.log("ğŸ¤– [generateAnswer] *** 19. ×§×•×¨× ×œ-openai.chat.completions.create ***")
    const completion = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
      temperature: 0.3,
      max_tokens: 800,
    })
    console.log("ğŸ¤– [generateAnswer] *** 20. openai.chat.completions.create ×”×•×©×œ× ***")

    console.log("ğŸ¤– [generateAnswer] *** 21. ××—×œ×¥ ×ª×©×•×‘×” ××”×ª×’×•×‘×” ***")
    const answer = completion.choices[0]?.message?.content || ""
    console.log("âœ… [generateAnswer] *** 22. ×ª×©×•×‘×” ×¨××©×•× ×™×ª × ×•×¦×¨×”! ***")
    console.log("ğŸ“ [generateAnswer] *** 23. ×ª×©×•×‘×”:", answer.substring(0, 200) + "... ***")
    console.log("ğŸ§ª [generateAnswer] *** 24. ×”×× ×™×© ×‘×›×œ×œ ×ª×©×•×‘×” ×œ×‘×“×•×§?", answer?.length, "×ª×•×•×™× ***")

    // ×‘×“×™×§×” ×× ×”×ª×©×•×‘×” ×¨×™×§×”
    console.log("ğŸ¤– [generateAnswer] *** 25. ×‘×•×“×§ ×× ×”×ª×©×•×‘×” ×¨×™×§×” ***")
    if (answer.trim().length === 0) {
      console.log("âš ï¸ [generateAnswer] *** 26. ×ª×©×•×‘×” ×¨×™×§×” â€“ ××¤×¢×™×œ Web Search ×™×©×™×¨×•×ª ***")
      return await searchWebWithOpenAI(question, language)
    }

    // ğŸ§  ×©×œ×‘ 3: ×‘×“×™×§×” ×¢× GPT ×”×× ×”×ª×©×•×‘×” ××¡×¤×§×ª - ×ª××™×“ ××ª×‘×¦×¢×ª!
    console.log("ğŸ” [generateAnswer] *** 27. ××ª×—×™×œ ×‘×“×™×§×ª ××™×›×•×ª ×”×ª×©×•×‘×” - ×ª××™×“ ××ª×‘×¦×¢×ª! ***")

    console.log("ğŸ¤– [generateAnswer] *** 28. ×§×•×¨× ×œ-isAnswerInsufficientByGPT ***")
    const isBadAnswer = await isAnswerInsufficientByGPT(question, answer, language)
    console.log("ğŸ¤– [generateAnswer] *** 29. isAnswerInsufficientByGPT ×”×•×©×œ× ***")

    console.log("ğŸ¯ [generateAnswer] *** 30. ×ª×•×¦××ª ×‘×“×™×§×ª ××™×›×•×ª:", isBadAnswer ? "âŒ ×œ× ××¡×¤×§×ª" : "âœ… ××¡×¤×§×ª", "***")

    console.log("ğŸ¤– [generateAnswer] *** 31. ×‘×•×“×§ ×× ×”×ª×©×•×‘×” ×œ× ××¡×¤×§×ª ***")
    if (isBadAnswer) {
      console.log("ğŸ” [generateAnswer] *** 32. ×”×ª×©×•×‘×” ×œ× ××¡×¤×§×ª ×œ×¤×™ GPT â€“ ×¢×•×‘×¨ ×œÖ¾Web Search ***")
      return await searchWebWithOpenAI(question, language)
    }

    console.log("âœ… [generateAnswer] *** 33. ×”×ª×©×•×‘×” × ×‘×“×§×” ×•× ××¦××” ××¡×¤×§×ª - ××©×ª××© ×‘×ª×©×•×‘×” ××”××¡××›×™× ***")

    console.log("ğŸ¤– [generateAnswer] *** 34. ××—×–×™×¨ ×ª×©×•×‘×” ×¡×•×¤×™×ª ***")
    return {
      answer,
      usedFallback: false,
      usedWebSearch: false,
    }
  } catch (error) {
    console.error("âŒ [generateAnswer] *** 35. ×©×’×™××” ×‘×™×¦×™×¨×ª ×ª×©×•×‘×”:", error, "***")

    if (error instanceof Error && error.message.includes("maximum context")) {
      console.log("ğŸ”„ [generateAnswer] *** 36: × ×™×¡×™×•×Ÿ ×—×•×–×¨ ×¢× ×¤×—×•×ª ××¡××›×™×... ***")
      const reducedDocuments = documents.slice(0, 1)
      return await generateAnswer(question, language)
    }

    // ×× ×™×© ×©×’×™××”, × × ×¡×” Web Search
    console.log("ğŸ”„ [generateAnswer] *** 37: ×©×’×™××” ×‘×™×¦×™×¨×ª ×ª×©×•×‘×”, ×¢×•×‘×¨ ×œ-Web Search... ***")
    return await searchWebWithOpenAI(question, language)
  }
}

// ×ª×©×•×‘×ª fallback ××§×•×¦×¨×ª
async function generateFallbackAnswer(
  question: string,
  language: "he" | "en",
): Promise<{ answer: string; usedFallback: boolean; usedWebSearch?: boolean }> {
  try {
    console.log("ğŸ”„ [generateFallbackAnswer] ×™×•×¦×¨ ×ª×©×•×‘×ª fallback...")

    const systemPrompt =
      language === "he"
        ? `×ª×Ÿ ×ª×©×•×‘×” ×§×¦×¨×” ×•××•×¢×™×œ×”. ×¦×™×™×Ÿ ×©×”××™×“×¢ ××™× ×• ××‘×•×¡×¡ ×¢×œ ××¡××›×™× ×¨×©××™×™× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£.`
        : `Provide a brief, helpful answer. Mention that information is not based on official Home Front Command documents.`

    const completion = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: question },
      ],
      temperature: 0.5,
      max_tokens: 300,
    })

    const answer = completion.choices[0]?.message?.content || ""
    console.log("âœ… [generateFallbackAnswer] ×ª×©×•×‘×ª fallback × ×•×¦×¨×” ×‘×”×¦×œ×—×”")

    return { answer, usedFallback: true, usedWebSearch: false }
  } catch (error) {
    console.error("âŒ [generateFallbackAnswer] ×©×’×™××” ×‘×™×¦×™×¨×ª ×ª×©×•×‘×ª fallback:", error)
    throw error
  }
}

// ×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª
export async function processRAGQuery(question: string): Promise<{
  answer: string
  sources: Array<{
    title: string
    file_name: string
    storage_path: string
    similarity: number
    sourceType: "official" | "web" | "ai_generated"
  }>
  usedFallback: boolean
  usedWebSearch?: boolean
  error?: string
}> {
  try {
    console.log("ğŸš€ [processRAGQuery] *** 1. ××ª×—×™×œ ×¢×™×‘×•×“ ×©××œ×” ***")
    console.log("ğŸš€ [processRAGQuery] *** 2. ×©××œ×”:", question, "***")

    // ×–×™×”×•×™ ×©×¤×”
    console.log("ğŸŒ [processRAGQuery] *** 3. ××–×”×” ×©×¤×” ***")
    const language = detectLanguage(question)
    console.log("ğŸŒ [processRAGQuery] *** 4. ×©×¤×” ×©×–×•×”×ª×”:", language, "***")

    // ×™×¦×™×¨×ª embedding
    console.log("ğŸ”„ [processRAGQuery] *** 5. ×™×•×¦×¨ embedding ***")
    const embedding = await createEmbedding(question)
    console.log("âœ… [processRAGQuery] *** 6. embedding × ×•×¦×¨ ×‘×”×¦×œ×—×” ***")

    // ×—×™×¤×•×© ××¡××›×™×
    console.log("ğŸ” [processRAGQuery] *** 7. ××—×¤×© ××¡××›×™× ***")
    const documents = await searchSimilarDocuments(embedding, language)
    console.log("âœ… [processRAGQuery] *** 8. ××¡××›×™× × ××¦××•:", documents.length, "***")

    // ×™×¦×™×¨×ª ×ª×©×•×‘×” - ×›××Ÿ ×§×•×¨×” ×”×§×¡×!
    console.log("ğŸ¤– [processRAGQuery] *** 9. ×§×•×¨× ×œ-generateAnswer - ×›××Ÿ ×ª×ª×‘×¦×¢ ×‘×“×™×§×ª ×”××™×›×•×ª ***")
    const { answer, usedFallback, usedWebSearch } = await generateAnswer(question, documents, language)
    console.log("âœ… [processRAGQuery] *** 10. generateAnswer ×”×•×©×œ× ***")

    console.log("ğŸ“Š [processRAGQuery] *** 11. ×ª×•×¦××•×ª generateAnswer ***")
    console.log("  - usedFallback:", usedFallback)
    console.log("  - usedWebSearch:", usedWebSearch)
    console.log("  - answer length:", answer.length)

    // ×”×›× ×ª ××§×•×¨×•×ª
    console.log("ğŸ“„ [processRAGQuery] *** 12. ××›×™×Ÿ ××§×•×¨×•×ª ×¨×’×™×œ×™×... ***")
    let sources: Array<{
      title: string
      file_name: string
      storage_path: string
      similarity: number
      sourceType: "official" | "web" | "ai_generated"
    }> = []

    if (usedWebSearch) {
      console.log("ğŸŒ [processRAGQuery] ××›×™×Ÿ ××§×•×¨×•×ª ×œweb search...")
      sources = [
        {
          title: "××™×“×¢ ××”××™× ×˜×¨× ×˜",
          file_name: "web_search",
          storage_path: "",
          similarity: 0,
          sourceType: "web",
        },
      ]
    } else if (usedFallback) {
      console.log("ğŸ¤– [processRAGQuery] ××›×™×Ÿ ××§×•×¨×•×ª ×œfallback...")
      sources = [
        {
          title: "×ª×©×•×‘×” ××‘×•×¡×¡×ª AI",
          file_name: "ai_generated",
          storage_path: "",
          similarity: 0,
          sourceType: "ai_generated",
        },
      ]
    } else {
      console.log("ğŸ“„ [processRAGQuery] ××›×™×Ÿ ××§×•×¨×•×ª ×¨×’×™×œ×™×...")
      sources = documents.map((doc) => ({
        title: doc.title,
        file_name: doc.file_name,
        storage_path: doc.storage_path,
        similarity: doc.similarity, // ×©×•××¨ ×¢×œ ×”×¢×¨×š ×”××§×•×¨×™
        sourceType: "official" as const,
      }))
    }

    console.log("âœ… [processRAGQuery] *** 13. ×¢×™×‘×•×“ ×”×•×©×œ× ×‘×”×¦×œ×—×” ***")

    return {
      answer,
      sources,
      usedFallback,
      usedWebSearch,
    }
  } catch (error) {
    console.error("âŒ [processRAGQuery] ×©×’×™××” ×›×œ×œ×™×ª ×‘×¢×™×‘×•×“:", error)

    return {
      answer: "××¦×˜×¢×¨, ××™×¨×¢×” ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×©××œ×” ×©×œ×š. ×× × × ×¡×” ×©×•×‘.",
      sources: [],
      usedFallback: true,
      usedWebSearch: false,
      error: error instanceof Error ? error.message : JSON.stringify(error),
    }
  }
}

// × ×™×”×•×œ ×©×™×—×•×ª - ×™×¦×™×¨×ª session ×—×“×© ×¢× user_id
export async function createChatSession(userId?: string): Promise<string> {
  try {
    console.log("ğŸ†• ×™×•×¦×¨ chat session ×—×“×© ×¢×‘×•×¨ user:", userId)

    const sessionData: any = {
      created_at: new Date().toISOString(),
    }

    // ×× ×™×© user_id, × ×•×¡×™×£ ××•×ª×•
    if (userId) {
      sessionData.user_id = userId
      console.log("ğŸ‘¤ ××•×¡×™×£ user_id ×œsession:", userId)
    }

    const { data, error } = await supabase.from("chat_sessions").insert(sessionData).select("id").single()

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª session:", error)
      throw error
    }

    console.log("âœ… Session × ×•×¦×¨ ×‘×”×¦×œ×—×”:", data.id)
    return data.id
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×¡×©×Ÿ:", error)
    throw error
  }
}

export async function saveChatMessage(
  sessionId: string,
  message: string,
  isUser: boolean,
  sources?: Array<{
    title: string
    file_name: string
    storage_path: string
    similarity: number
    sourceType?: "official" | "web" | "ai_generated"
  }>,
): Promise<void> {
  try {
    console.log(`ğŸ’¾ ×©×•××¨ ×”×•×“×¢×”: ${isUser ? "××©×ª××©" : "×‘×•×˜"} - ${message.substring(0, 50)}...`)
    console.log(`ğŸ“Š ××§×•×¨×•×ª ×œ×©××™×¨×”:`, sources?.length || 0)

    const { error } = await supabase.from("chat_messages").insert({
      session_id: sessionId,
      content: message,
      role: isUser ? "user" : "assistant",
      sources: sources || [],
      created_at: new Date().toISOString(),
    })

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×•×“×¢×”:", error)
      throw error
    }

    console.log("âœ… ×”×•×“×¢×” × ×©××¨×” ×‘×”×¦×œ×—×”")
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×•×“×¢×”:", error)
    throw error
  }
}

export async function getChatHistory(sessionId: string): Promise<
  Array<{
    id: string
    content: string
    role: string
    sources: Array<{
      title: string
      file_name: string
      storage_path: string
      similarity: number
      sourceType?: "official" | "web" | "ai_generated"
    }>
    created_at: string
  }>
> {
  try {
    console.log("ğŸ“š ×˜×•×¢×Ÿ ×”×™×¡×˜×•×¨×™×™×ª ×¦'××˜ ×¢×‘×•×¨ session:", sessionId)

    const { data, error } = await supabase
      .from("chat_messages")
      .select("*")
      .eq("session_id", sessionId)
      .order("created_at", { ascending: true })

    if (error) {
      console.error("âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×”:", error)
      throw error
    }

    console.log(`âœ… × ×˜×¢× ×• ${data?.length || 0} ×”×•×“×¢×•×ª`)
    return data || []
  } catch (error) {
    console.error("âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×”:", error)
    return []
  }
}
