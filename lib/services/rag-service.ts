import { createClient } from "@supabase/supabase-js"
import OpenAI from "openai"

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!)
console.log(" [RAG Service] Loaded from: lib/services/rag-service.ts")

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
})

//  砖驻 驻砖
function detectLanguage(text: string): "he" | "en" {
  const hebrewPattern = /[\u0590-\u05FF]/
  return hebrewPattern.test(text) ? "he" : "en"
}

// 爪专转 embedding 砖
async function createEmbedding(text: string): Promise<number[]> {
  try {
    const response = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: text,
    })
    return response.data[0].embedding
  } catch (error) {
    console.error("Error creating embedding:", error)
    throw new Error("Failed to create embedding")
  }
}

// 驻砖 住 
async function searchSimilarDocuments(embedding: number[], language: string, matchThreshold = 0.7, matchCount = 5) {
  try {
    const { data, error } = await supabase.rpc("match_documents", {
      query_embedding: embedding,
      match_threshold: matchThreshold,
      match_count: matchCount,
      filter_language: language,
    })

    if (error) {
      console.error("Error searching documents:", error)
      return []
    }

    return data || []
  } catch (error) {
    console.error("Error in searchSimilarDocuments:", error)
    return []
  }
}

// Step-back prompting template
const STEPBACK_PROMPT = `
转 注专  砖 驻拽 注专祝 砖专. 转驻拽 住驻拽 转砖转 拽转, 转 注转 砖转 拽砖专转 爪 专 砖专.

驻 转 转砖, 拽 爪注 专 砖  注 专 专砖  注转 注 砖 爪专 拽转 .

砖 驻砖转:
- 注  砖  注住拽转 住?
-  住 转砖 爪专 转转 (驻专爪专转, 注转转, 住住转 转)?

砖转砖 专拽 注   注转 注专转 专专 转转 爪专:

拽砖专 专:
{context}

砖:
{question}

转砖:
`

// Fallback prompt
const FALLBACK_PROMPT = `
转 注专  砖 驻拽 注专祝. 注 注 砖  转住住 注 注  砖:

砖: {question}

转砖:
`

// 爪专转 转砖 注 Step-back prompting
async function generateAnswer(question: string, documents: any[], useStepback = true): Promise<string> {
  try {
    if (documents.length === 0) {
      // Fallback - 转砖 转
      const response = await openai.chat.completions.create({
        model: "gpt-4",
        messages: [
          {
            role: "user",
            content: FALLBACK_PROMPT.replace("{question}", question),
          },
        ],
        temperature: 0.1,
        max_tokens: 500,
      })

      const answer = response.choices[0]?.message?.content || "爪注专,  爪转 爪专 转砖."
      return answer + "\n\n(注专: 转砖  转 驻  驻 转 注专转,  住转转 注 住 转.)"
    }

    // 爪专转 拽砖专 住
    const context = documents.map((doc, index) => `住 ${index + 1}:\n${doc.plain_text}`).join("\n\n---\n\n")

    const prompt = useStepback ? STEPBACK_PROMPT : STEPBACK_PROMPT
    const finalPrompt = prompt.replace("{context}", context).replace("{question}", question)

    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        {
          role: "user",
          content: finalPrompt,
        },
      ],
      temperature: 0.1,
      max_tokens: 500,
    })

    return response.choices[0]?.message?.content || "爪注专,  爪转 爪专 转砖."
  } catch (error) {
    console.error("Error generating answer:", error)
    throw new Error("Failed to generate answer")
  }
}

// 驻拽爪 专砖转 砖 RAG
export async function processRAGQuery(question: string) {
  try {
      console.log(" [RAG Service] Executing processRAGQuery from: lib/services/rag-service.ts")
    console.log("Processing RAG query:", question)

    // 砖 1:  砖驻
    const language = detectLanguage(question)
    console.log("Detected language:", language)

    // 砖 2: 爪专转 embedding
    const embedding = await createEmbedding(question)
    console.log("Created embedding, length:", embedding.length)

    // 砖 3: 驻砖 住 
    const documents = await searchSimilarDocuments(embedding, language)
    console.log("Found documents:", documents.length)

    // 砖 4: 爪专转 转砖
    const answer = await generateAnswer(question, documents, true)

    return {
      answer,
      sources: documents.map((doc) => ({
        title: doc.title,
        file_name: doc.file_name,
        similarity: doc.similarity,
      })),
      language,
      documentsFound: documents.length,
    }
  } catch (error) {
    console.error("Error in processRAGQuery:", error)
    return {
      answer: "爪注专, 专注 砖 注 砖 砖.  住 砖.",
      sources: [],
      language: "he",
      documentsFound: 0,
      error: error instanceof Error ? error.message : "Unknown error",
    }
  }
}

//  住砖
export async function createChatSession(userId: string, title?: string) {
  try {
    const { data, error } = await supabase
      .from("chat_sessions")
      .insert({
        user_id: userId,
        title: title || "砖 砖",
      })
      .select()
      .single()

    if (error) throw error
    return data
  } catch (error) {
    console.error("Error creating chat session:", error)
    throw error
  }
}

// 砖专转 注
export async function saveChatMessage(sessionId: string, role: "user" | "assistant", content: string) {
  try {
    const { data, error } = await supabase
      .from("chat_messages")
      .insert({
        session_id: sessionId,
        role,
        content,
      })
      .select()
      .single()

    if (error) throw error
    return data
  } catch (error) {
    console.error("Error saving chat message:", error)
    throw error
  }
}

// 注转 住专转 砖
export async function getChatHistory(sessionId: string) {
  try {
    const { data, error } = await supabase
      .from("chat_messages")
      .select("*")
      .eq("session_id", sessionId)
      .order("created_at", { ascending: true })

    if (error) throw error
    return data || []
  } catch (error) {
    console.error("Error getting chat history:", error)
    return []
  }
}

// 注转 住砖 砖 砖转砖
export async function getUserChatSessions(userId: string) {
  try {
    const { data, error } = await supabase
      .from("chat_sessions")
      .select("*")
      .eq("user_id", userId)
      .order("created_at", { ascending: false })

    if (error) throw error
    return data || []
  } catch (error) {
    console.error("Error getting user chat sessions:", error)
    return []
  }
}
