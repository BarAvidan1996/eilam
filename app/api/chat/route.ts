import { OpenAIStream, StreamingTextResponse } from "ai"
import OpenAI from "openai"
import { processRAGQuery, saveChatMessage } from "@/lib/rag-service"

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export async function POST(request: Request) {
  try {
    const body = await request.json()
    console.log("ğŸ¯ Chat API - ×§×™×‘×œ×ª×™ ×‘×§×©×”:", body)

    // useChat ×©×•×œ×— messages array ×•-sessionId ×‘× ×¤×¨×“
    const { messages, sessionId } = body

    // ×”×•×“×¢×” ××—×¨×•× ×” ×”×™× ×”×©××œ×” ×”× ×•×›×—×™×ª
    const lastMessage = messages[messages.length - 1]
    const message = lastMessage?.content

    console.log("ğŸ“ Extracted data:", { message, sessionId, messagesCount: messages?.length })

    if (!message || !sessionId) {
      console.log("âŒ Missing data:", { hasMessage: !!message, hasSessionId: !!sessionId })
      return new Response(JSON.stringify({ error: "Missing message or sessionId" }), {
        status: 400,
        headers: { "Content-Type": "application/json" },
      })
    }

    // ×©××™×¨×ª ×”×•×“×¢×ª ×”××©×ª××©
    await saveChatMessage(sessionId, message, true)

    // ×¢×™×‘×•×“ RAG
    const ragResult = await processRAGQuery(message)

    console.log(
      "ğŸ“Š RAG Result sources:",
      ragResult.sources?.map((s) => ({
        title: s.title,
        similarity: Math.round(s.similarity * 100) + "%",
      })),
    )

    // ×”×›× ×ª ×”×§×©×¨ ×œ××•×“×œ
    let context = ""
    if (ragResult.sources && ragResult.sources.length > 0) {
      context = ragResult.sources.map((source) => `××§×•×¨: ${source.title}\n×ª×•×›×Ÿ: ${source.content}`).join("\n\n")
    }

    const systemPrompt = `××ª×” ×¢×™×œ"×, ×¢×•×–×¨ ×”×—×™×¨×•× ×”××™×©×™ ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. 
×ª×Ÿ ×ª×©×•×‘×” ×§×¦×¨×” ×•××“×•×™×§×ª ×‘×¢×‘×¨×™×ª ×‘×”×ª×‘×¡×¡ ×¢×œ ×”××™×“×¢ ×”××¡×•×¤×§.
${context ? `\n\n××™×“×¢ ×¨×œ×•×•× ×˜×™:\n${context}` : ""}`

    // ×™×¦×™×¨×ª streaming response ×¢× OpenAI ×™×©×™×¨×•×ª
    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: message },
      ],
      temperature: 0.3,
      max_tokens: 800,
      stream: true,
    })

    // ×”××¨×” ×œ-stream ×©×œ Vercel
    const stream = OpenAIStream(response, {
      onCompletion: async (completion) => {
        // ×©××™×¨×ª ×”×ª×©×•×‘×” ×”××œ××” ××—×¨×™ ×©×”×™× ××¡×ª×™×™××ª
        await saveChatMessage(sessionId, completion, false, ragResult.sources)
      },
    })

    // ×”×—×–×¨×ª streaming response ×¢× metadata
    return new StreamingTextResponse(stream, {
      headers: {
        "X-Sources": JSON.stringify(ragResult.sources || []),
        "X-Used-Fallback": ragResult.usedFallback.toString(),
      },
    })
  } catch (error) {
    console.error("ğŸ’¥ Chat API Error:", error)
    return new Response(
      JSON.stringify({
        error: "Internal server error",
        details: error instanceof Error ? error.message : "Unknown error",
      }),
      { status: 500, headers: { "Content-Type": "application/json" } },
    )
  }
}
