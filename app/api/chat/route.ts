import { streamText } from "ai"
import { openai } from "@ai-sdk/openai"
import { processRAGQuery, saveChatMessage } from "@/lib/rag-service"

export async function POST(req: Request) {
  console.log("ğŸš€ API Chat - ×”×ª×—×œ×ª ×¢×™×‘×•×“ ×‘×§×©×”")

  try {
    const body = await req.json()
    console.log("ğŸ“¦ ×’×•×£ ×”×‘×§×©×” ×©×”×ª×§×‘×œ:", JSON.stringify(body, null, 2))

    const { messages, sessionId } = body

    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      console.log("âŒ ×©×’×™××”: messages ×œ× ×ª×§×™×Ÿ")
      return new Response("Messages are required", { status: 400 })
    }

    if (!sessionId || typeof sessionId !== "string") {
      console.log("âŒ ×©×’×™××”: sessionId ×œ× ×ª×§×™×Ÿ")
      return new Response("SessionId is required", { status: 400 })
    }

    console.log("âœ… ×¤×¨××˜×¨×™× ×ª×§×™× ×™×, ××ª×—×™×œ ×¢×™×‘×•×“")

    // ×”×”×•×“×¢×” ×”××—×¨×•× ×” ×”×™× ×”×©××œ×” ×©×œ ×”××©×ª××©
    const lastMessage = messages[messages.length - 1]
    const userQuestion = lastMessage.content

    console.log("ğŸ’¬ ×©××œ×ª ×”××©×ª××©:", userQuestion)

    // ×©××™×¨×ª ×”×•×“×¢×ª ×”××©×ª××©
    console.log("ğŸ’¾ ×©×•××¨ ×”×•×“×¢×ª ××©×ª××©...")
    await saveChatMessage(sessionId, userQuestion, true)

    // ×¢×™×‘×•×“ RAG
    console.log("ğŸ§  ××ª×—×™×œ ×¢×™×‘×•×“ RAG...")
    const ragResult = await processRAGQuery(userQuestion)

    console.log("ğŸ“Š ×ª×•×¦××ª RAG:", {
      answerLength: ragResult.answer.length,
      sourcesCount: ragResult.sources.length,
      usedFallback: ragResult.usedFallback,
    })

    // ×™×¦×™×¨×ª streaming response ×¢× Vercel AI SDK
    const result = await streamText({
      model: openai("gpt-4"),
      messages: [
        {
          role: "system",
          content: `××ª×” ×¢×™×œ"×, ×¢×•×–×¨ ×”×—×™×¨×•× ×©×œ ×¤×™×§×•×“ ×”×¢×•×¨×£. 
          ×”×¦×’ ××ª ×”×ª×©×•×‘×” ×”×‘××” ×‘×¦×•×¨×” ×˜×‘×¢×™×ª ×•×—×œ×§×”:
          
          ${ragResult.answer}`,
        },
        {
          role: "user",
          content: userQuestion,
        },
      ],
      temperature: 0.1,
      maxTokens: 1000,
      onFinish: async (result) => {
        // ×©××™×¨×ª ×ª×©×•×‘×ª ×”×‘×•×˜ ××—×¨×™ ×©×”streaming ××¡×ª×™×™×
        console.log("ğŸ’¾ ×©×•××¨ ×ª×©×•×‘×ª ×‘×•×˜...")
        await saveChatMessage(sessionId, result.text, false, ragResult.sources)
        console.log("âœ… ×ª×©×•×‘×ª ×‘×•×˜ × ×©××¨×” ×‘×”×¦×œ×—×”")
      },
    })

    // ×”×•×¡×¤×ª metadata ×œ××˜×-×“××˜×” ×©×œ ×”response
    return result.toAIStreamResponse({
      headers: {
        "X-RAG-Sources": JSON.stringify(ragResult.sources),
        "X-RAG-Fallback": ragResult.usedFallback.toString(),
        "X-Session-ID": sessionId,
      },
    })
  } catch (error) {
    console.error("ğŸ’¥ ×©×’×™××” ×›×œ×œ×™×ª ×‘-API:")
    console.error("  - Error type:", error?.constructor?.name)
    console.error("  - Error message:", error instanceof Error ? error.message : String(error))
    console.error("  - Error stack:", error instanceof Error ? error.stack : "No stack")

    return new Response(
      JSON.stringify({
        error: "×©×’×™××” ×¤× ×™××™×ª ×‘×©×¨×ª",
        debugError: error instanceof Error ? error.message : JSON.stringify(error),
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" },
      },
    )
  }
}
